{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee54026",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df8b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.applications import Xception, DenseNet201\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import random\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bdc0a1",
   "metadata": {},
   "source": [
    "# global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8010278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size options: 192, 224, 311, 512\n",
    "IMAGE_DIMENSION = 192\n",
    "VECTOR_LEN = IMAGE_DIMENSION**2\n",
    "NUM_CLASS = 96\n",
    "\n",
    "train_dir = f'data/jpeg-{IMAGE_DIMENSION}x{IMAGE_DIMENSION}/train'\n",
    "val_dir = f'data/jpeg-{IMAGE_DIMENSION}x{IMAGE_DIMENSION}/val'\n",
    "test_dir = f'data/jpeg-{IMAGE_DIMENSION}x{IMAGE_DIMENSION}/test'\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982acf98",
   "metadata": {},
   "source": [
    "# eda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eafce0",
   "metadata": {},
   "source": [
    "# generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8bb62c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11459 images belonging to 104 classes.\n",
      "Found 3710 images belonging to 104 classes.\n",
      "Found 1294 images belonging to 104 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7456973",
   "metadata": {},
   "source": [
    "### defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79170f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subfolder_list(source_folder):\n",
    "    # returns a list of all the subfolders in the source_folder\n",
    "    class_list_dir = []\n",
    "\n",
    "    for file in os.listdir(source_folder):\n",
    "        d = os.path.join(source_folder, file)\n",
    "        if os.path.isdir(d):\n",
    "            class_list_dir.append(d)\n",
    "\n",
    "    return class_list_dir\n",
    "\n",
    "def map_classes(subfolder_list):\n",
    "    # returns a dict with the flower as the key, and (count, directory) as the values\n",
    "    class_dict = {}\n",
    "\n",
    "    for class_folder in subfolder_list:\n",
    "        file_count = sum(len(files) for _, _, files in os.walk(class_folder))\n",
    "        class_dict[class_folder[24:]] = file_count, class_folder\n",
    "        \n",
    "    return class_dict\n",
    "\n",
    "def get_flower_count(class_dict):\n",
    "    # returns a list of the number of flowers found in the dict\n",
    "    flower_count = []\n",
    "\n",
    "    for flower in list(class_dict.values()):\n",
    "        flower_count.append(flower[0])\n",
    "\n",
    "    return flower_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5578dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(flower_count):\n",
    "    # returns basic metrics when given a list of flower value count\n",
    "    class_std = np.std(flower_count)\n",
    "    class_max = max(flower_count)\n",
    "    class_min = min(flower_count)\n",
    "    class_mean = np.mean(flower_count)\n",
    "    class_first_quartile = np.percentile(flower_count, 25)\n",
    "    class_third_quartile = np.percentile(flower_count, 75)\n",
    "    class_tenth_percentile = np.percentile(flower_count, 10)\n",
    "    class_fifth_percentile = np.percentile(flower_count, 5)\n",
    "\n",
    "    print(f'0. standard deviation: {class_std}')\n",
    "    print(f'1. max: {class_max}')\n",
    "    print(f'2. min: {class_min}')\n",
    "    print(f'3. mean: {class_mean}')\n",
    "    print(f'4. 25%: {class_first_quartile}')\n",
    "    print(f'5. 75%: {class_third_quartile}')\n",
    "    print(f'6. 10%: {class_tenth_percentile}')\n",
    "    print(f'7. 5%: {class_fifth_percentile}')\n",
    "    \n",
    "    return (class_std, class_max, class_min, class_mean, class_first_quartile,\n",
    "class_third_quartile, class_tenth_percentile, class_fifth_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab5257",
   "metadata": {},
   "source": [
    "### testing above functions / eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa598df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subfolders = get_subfolder_list(train_dir)\n",
    "train_dict = map_classes(train_subfolders)\n",
    "train_flower_count = get_flower_count(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bcfb6cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/jpeg-192x192/train/toad lily',\n",
       " 'data/jpeg-192x192/train/love in the mist',\n",
       " 'data/jpeg-192x192/train/monkshood',\n",
       " 'data/jpeg-192x192/train/azalea',\n",
       " 'data/jpeg-192x192/train/fritillary']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subfolders[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6d3411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. standard deviation: 132.99130714962862\n",
      "1. max: 707\n",
      "2. min: 16\n",
      "3. mean: 111.1826923076923\n",
      "4. 25%: 30.5\n",
      "5. 75%: 113.5\n",
      "6. 10%: 19.0\n",
      "7. 5%: 17.15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(132.99130714962862, 707, 16, 111.1826923076923, 30.5, 113.5, 19.0, 17.15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(train_flower_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ef0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subfolders = get_subfolder_list(val_dir)\n",
    "val_dict = map_classes(val_subfolders)\n",
    "val_flower_count = get_flower_count(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "614f469e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. standard deviation: 42.990624407913046\n",
      "1. max: 228\n",
      "2. min: 5\n",
      "3. mean: 35.69230769230769\n",
      "4. 25%: 9.0\n",
      "5. 75%: 37.0\n",
      "6. 10%: 6.0\n",
      "7. 5%: 6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42.990624407913046, 228, 5, 35.69230769230769, 9.0, 37.0, 6.0, 6.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(val_flower_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d43686",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e12ece",
   "metadata": {},
   "source": [
    "### more functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf7ad0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_subfolder(source):\n",
    "    # copies source folder to a new directory with '_new' attached to the end of the folder name\n",
    "    prev_dir_index = source.rfind('/')\n",
    "    destination = source[:prev_dir_index] + '_new' + source[prev_dir_index:]\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(destination):\n",
    "        result = shutil.copytree(source, destination, symlinks=False, ignore=None, \n",
    "                                 copy_function=shutil.copy2, ignore_dangling_symlinks=False, \n",
    "                                 dirs_exist_ok=False)\n",
    "    else:\n",
    "        print(f'{destination} already exists')\n",
    "        \n",
    "    return result\n",
    "    \n",
    "def item_count(folder):\n",
    "    # helper function to identify which folders to remove\n",
    "    file_count = sum(len(files) for _, _, files in os.walk(folder))\n",
    "    \n",
    "    return file_count\n",
    "    \n",
    "def get_short_list(subfolder_list, n):\n",
    "    # find a list of classes that are divided by the specified n value\n",
    "    temp_dict = map_classes(subfolder_list)\n",
    "    temp_flower_count = get_flower_count(temp_dict)\n",
    "    \n",
    "    move_list = []\n",
    "    ignore_list = []\n",
    "    \n",
    "    percent_cutoff = np.percentile(temp_flower_count, n)\n",
    "    \n",
    "    for subfolder in subfolder_list:\n",
    "        if item_count(subfolder) >= percent_cutoff:\n",
    "            move_list.append(subfolder)\n",
    "        else:\n",
    "            ignore_list.append(subfolder)\n",
    "            \n",
    "    return move_list, ignore_list\n",
    "    \n",
    "def trim(subfolder_list):\n",
    "    # main function used to copy classes into new train, val, test \n",
    "    for subfolder in subfolder_list:\n",
    "        copy_subfolder(subfolder)\n",
    "\n",
    "        val_subfolder = subfolder.replace('/train/', '/val/')\n",
    "        copy_subfolder(val_subfolder)\n",
    "\n",
    "        test_subfolder = subfolder.replace('/train/', '/test/')\n",
    "        copy_subfolder(test_subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecf01414",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_list, ignore_list = get_short_list(train_subfolders, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3821f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/jpeg-192x192/train/toad lily',\n",
       " 'data/jpeg-192x192/train/love in the mist',\n",
       " 'data/jpeg-192x192/train/monkshood',\n",
       " 'data/jpeg-192x192/train/azalea',\n",
       " 'data/jpeg-192x192/train/fritillary']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c20376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/jpeg-192x192/train_new/toad lily already exists\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'result' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fh/_3l8mb_s4j967nwd3wg1v2d40000gn/T/ipykernel_41427/3298806049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/fh/_3l8mb_s4j967nwd3wg1v2d40000gn/T/ipykernel_41427/394949064.py\u001b[0m in \u001b[0;36mtrim\u001b[0;34m(subfolder_list)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# main function used to copy classes into new train, val, test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubfolder_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mcopy_subfolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mval_subfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/train/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/val/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fh/_3l8mb_s4j967nwd3wg1v2d40000gn/T/ipykernel_41427/394949064.py\u001b[0m in \u001b[0;36mcopy_subfolder\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{destination} already exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mitem_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'result' referenced before assignment"
     ]
    }
   ],
   "source": [
    "trim(move_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee979b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the directories as new folders are made \n",
    "train_dir = f'data/jpeg-{IMAGE_DIMENSION}x{IMAGE_DIMENSION}/train_new'\n",
    "val_dir = f'data/jpeg-{IMAGE_DIMENSION}x{IMAGE_DIMENSION}/val_new'\n",
    "test_dir = f'data/jpeg-{IMAGE_DIMENSION}x{IMAGE_DIMENSION}/test_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905bd2a",
   "metadata": {},
   "source": [
    "# generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3aa29",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383fecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        strides=(1,1),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,4)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5, input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7bd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079df1b",
   "metadata": {},
   "source": [
    "### simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8dcc4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=64, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894d303",
   "metadata": {},
   "source": [
    "### simple model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493ca72",
   "metadata": {},
   "source": [
    "### simple 2 - another layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (2,2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6049e91",
   "metadata": {},
   "source": [
    "### simple 3 - change the kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae34fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa48c237",
   "metadata": {},
   "source": [
    "### simple 4 - batch size increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed2be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0237bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39326fce",
   "metadata": {},
   "source": [
    "### simple 5 - further batch size increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7329bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411417f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699818fb",
   "metadata": {},
   "source": [
    "### simple 6 - revert to simple 4. add another dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebd661",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a83948",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a9215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6d630",
   "metadata": {},
   "source": [
    "### simple 7 - adjust learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b29645",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5193ae",
   "metadata": {},
   "source": [
    "### simple 8 - improving generalization. add dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc350cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6b5a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df6d76",
   "metadata": {},
   "source": [
    "### simple 9 - more generalization. increase dropout %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e9da0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropoutout(0.6))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb77802",
   "metadata": {},
   "source": [
    "### simple 10. revert to simple 7 and apply normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2246374e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.BatchNormalizationtchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f30369",
   "metadata": {},
   "source": [
    "### simple 11. revert to simple 7. more epochs and smaller batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb152e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f83dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af832628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=50,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60c0b5a",
   "metadata": {},
   "source": [
    "### simple 12. revert to simple 7. use sgd instead of adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d762d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548242d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469855f",
   "metadata": {},
   "source": [
    "### simple 13. revert to simple 7. still need to reduce overfitting. attempt different data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afbf9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc879ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=60,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.4,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb69512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda74094",
   "metadata": {},
   "source": [
    "### simple 14. revert to simple 7. adding more layers. sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a32c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a34dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486287e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Conv2D(8, (4,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((4,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fdd798",
   "metadata": {},
   "source": [
    "### simple 15. use simple 14 but with adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501dedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d56831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Conv2D(8, (4,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((4,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea79e2",
   "metadata": {},
   "source": [
    "### exact copy of simple 7. running for reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8494c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36332876",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff351a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ead7b5",
   "metadata": {},
   "source": [
    "### adding more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e0773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=100,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9dd8c1",
   "metadata": {},
   "source": [
    "### need to reduce overfitting / improve generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7342762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3fe081",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e6be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e39bdf",
   "metadata": {},
   "source": [
    "### simple 7a. soft max activation, dense 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3021903",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f136a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fe3ab",
   "metadata": {},
   "source": [
    "### rerun simple7a with activation function after dense 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ce5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ef4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42693aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705b62a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f888d",
   "metadata": {},
   "source": [
    "### simple7a but with channelshiftrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea04612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     channel_shift_range=10\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9633f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32acfe0",
   "metadata": {},
   "source": [
    "### new model. global average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a321e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a5619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ac5f5",
   "metadata": {},
   "source": [
    "### transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "    include_top=False)\n",
    "\n",
    "Xception_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db789c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7321352",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be1c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Xception_model)\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d48e87",
   "metadata": {},
   "source": [
    "### simplest transfer model I could think of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab205874",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "    include_top=False)\n",
    "\n",
    "Xception_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9753fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a81a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Xception_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=50,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f46e15",
   "metadata": {},
   "source": [
    "### reduce overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b3305",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "    include_top=False)\n",
    "\n",
    "Xception_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a45e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "#                                      rotation_range=45,\n",
    "#                                      vertical_flip=False,\n",
    "#                                      brightness_range=[0.75,1.25],\n",
    "#                                      zoom_range=0.2,\n",
    "#                                      shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c9eab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Xception_model)\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db9b3b",
   "metadata": {},
   "source": [
    "### attempt to do some cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "    include_top=False)\n",
    "\n",
    "Xception_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e000ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "#                                      rotation_range=45,\n",
    "#                                      vertical_flip=False,\n",
    "#                                      brightness_range=[0.75,1.25],\n",
    "#                                      zoom_range=0.2,\n",
    "#                                      shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e5ede",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "          \n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "          \n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "          \n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "          \n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=50,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba5639",
   "metadata": {},
   "source": [
    "### above model with xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725aad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "    include_top=False)\n",
    "\n",
    "Xception_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99280b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "#                                      rotation_range=45,\n",
    "#                                      vertical_flip=False,\n",
    "#                                      brightness_range=[0.75,1.25],\n",
    "#                                      zoom_range=0.2,\n",
    "#                                      shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad474b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Xception_model)\n",
    "\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "          \n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "          \n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=50,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb4e44",
   "metadata": {},
   "source": [
    "### models with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddd29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "    include_top=False)\n",
    "\n",
    "Xception_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a99eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Xception_model)\n",
    "\n",
    "model.add(layers.Conv2D(filters=32, \n",
    "                        kernel_size=(2,2),\n",
    "                        activation='relu',\n",
    "                        padding = 'same',\n",
    "                        input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "                        data_format = 'channels_last'))\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "          \n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "          \n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=50,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee03fd32",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f160b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81d6147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "    include_top=False)\n",
    "\n",
    "Xception_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b87b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7719dc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11331 images belonging to 96 classes.\n",
      "Found 3666 images belonging to 96 classes.\n",
      "Found 1271 images belonging to 96 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9e1ec58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 6, 6, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 96)                196704    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96)                0         \n",
      "=================================================================\n",
      "Total params: 21,058,184\n",
      "Trainable params: 21,003,656\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x29f997160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x29f997160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 10:01:00.109030: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-05 10:01:00.109538: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - ETA: 0s - loss: 2.3999 - accuracy: 0.4484 WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x172734310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x172734310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "177/177 [==============================] - 2663s 15s/step - loss: 2.3955 - accuracy: 0.4493 - val_loss: 3583.6299 - val_accuracy: 0.0169\n",
      "Epoch 2/50\n",
      "177/177 [==============================] - 2279s 13s/step - loss: 0.7072 - accuracy: 0.8042 - val_loss: 1203.3223 - val_accuracy: 0.0161\n",
      "Epoch 3/50\n",
      "177/177 [==============================] - 2121s 12s/step - loss: 0.5080 - accuracy: 0.8587 - val_loss: 613.9814 - val_accuracy: 0.0177\n",
      "Epoch 4/50\n",
      "177/177 [==============================] - 2180s 12s/step - loss: 0.4587 - accuracy: 0.8664 - val_loss: 468.7973 - val_accuracy: 0.0330\n",
      "Epoch 5/50\n",
      "177/177 [==============================] - 1998s 11s/step - loss: 0.3640 - accuracy: 0.8951 - val_loss: 1897.8486 - val_accuracy: 0.0333\n",
      "Epoch 6/50\n",
      "177/177 [==============================] - 2028s 11s/step - loss: 0.2866 - accuracy: 0.9124 - val_loss: 6486.9204 - val_accuracy: 0.0158\n",
      "Epoch 7/50\n",
      "177/177 [==============================] - 2044s 12s/step - loss: 0.3487 - accuracy: 0.8957 - val_loss: 303.2917 - val_accuracy: 0.0161\n",
      "Epoch 8/50\n",
      "177/177 [==============================] - 2144s 12s/step - loss: 0.2359 - accuracy: 0.9311 - val_loss: 173.1927 - val_accuracy: 0.0270\n",
      "Epoch 9/50\n",
      "177/177 [==============================] - 2059s 12s/step - loss: 0.2117 - accuracy: 0.9360 - val_loss: 168.5182 - val_accuracy: 0.0453\n",
      "Epoch 10/50\n",
      "177/177 [==============================] - 2123s 12s/step - loss: 0.2029 - accuracy: 0.9365 - val_loss: 1443.1604 - val_accuracy: 0.0333\n",
      "Epoch 11/50\n",
      "177/177 [==============================] - 1976s 11s/step - loss: 0.1530 - accuracy: 0.9566 - val_loss: 722.6960 - val_accuracy: 0.0336\n",
      "Epoch 12/50\n",
      "177/177 [==============================] - 1995s 11s/step - loss: 0.1277 - accuracy: 0.9639 - val_loss: 649.1703 - val_accuracy: 0.0327\n",
      "Epoch 13/50\n",
      "145/177 [=======================>......] - ETA: 6:42 - loss: 0.1029 - accuracy: 0.9711"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fh/_3l8mb_s4j967nwd3wg1v2d40000gn/T/ipykernel_41427/4270006505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# training begins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=50,\n\u001b[0m\u001b[1;32m     15\u001b[0m           validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Xception_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=50,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f0242",
   "metadata": {},
   "source": [
    "### reducing runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7f37023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return 0.00001\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3617ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),\n",
    "    include_top=False)\n",
    "\n",
    "Xception_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "442d174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "TEST_BATCH_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be1a1eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11331 images belonging to 96 classes.\n",
      "Found 3666 images belonging to 96 classes.\n",
      "Found 1271 images belonging to 96 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     horizontal_flip=True, \n",
    "                                     rotation_range=45,\n",
    "                                     vertical_flip=False,\n",
    "                                     brightness_range=[0.75,1.25],\n",
    "                                     zoom_range=0.2,\n",
    "                                     shear_range=0.2\n",
    "                                    ).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION), \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION),\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5b60c4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 6, 6, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 96)                196704    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 96)                0         \n",
      "=================================================================\n",
      "Total params: 21,058,184\n",
      "Trainable params: 21,003,656\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x3c7b34670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x3c7b34670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 5/88 [>.............................] - ETA: 1:53:57 - loss: 4.4474 - accuracy: 0.0649"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fh/_3l8mb_s4j967nwd3wg1v2d40000gn/T/ipykernel_41427/202438389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# training begins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n\u001b[0m\u001b[1;32m     16\u001b[0m           validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/apple_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Xception_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(NUM_CLASS)) # output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training begins\n",
    "model.fit(train_generator, steps_per_epoch=11331 // BATCH_SIZE, epochs=20,\n",
    "          validation_data=val_generator, callbacks=lr_callback, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbd605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
